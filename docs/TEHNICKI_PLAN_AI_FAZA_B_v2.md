TEHNIÄŒKI PLAN: AI FAZA B (ORKESTRATOR) v2.0
I. UVOD: Evolucija Arhitekture 4.0 u Stateful Multi-Agentni Sustav
1.1 SaÅ¾etak Originalne Arhitekture (v4.0)
Inicijalna arhitektonska vizija (Arhitektura 4.0) definirana je kao strogo sekvencijalni agentni lanac. Ovaj je lanac dizajniran za izvrÅ¡avanje zadataka kreativnog pisanja kroz tri fiksne uloge:   

"LogistiÄar" (TypeScript Kod): Prima korisniÄki upit, izvodi Retrieval-Augmented Generation (RAG) pretraÅ¾ivanje vektorske baze i sastavlja JSON s kontekstom.

"AI Mentor" (Lokalni LLM): Prima JSON i pretvara ga u "savrÅ¡eni prompt" za pisanje.

"Pisac" (Cloud LLM): Prima "savrÅ¡eni prompt" i generira konaÄni kreativni tekst.

Glavni cilj ovog dizajna bio je eksplicitna prioritetizacija kvalitete konaÄnog izlaza, prihvaÄ‡ajuÄ‡i potencijalno veÄ‡u latenciju kao kompromis za postizanje vrhunskih rezultata. MeÄ‘utim, detaljna analiza identificira fundamentalno ograniÄenje: 100% sekvencijalni i linearni dizajn je krut. Ova krutost onemoguÄ‡uje implementaciju naprednijih, dinamiÄkih agentnih obrazacaâ€”kao Å¡to su iterativne petlje poboljÅ¡anja, uvjetno usmjeravanje zadataka i suradniÄka dinamikaâ€”koji su se pokazali kljuÄnima za postizanje najviÅ¡e razine kvalitete u sloÅ¾enim zadacima.   

1.2 Predstavljanje Arhitekture v2.0: Prelazak na Agentni Graf
Kao odgovor na ograniÄenja v4.0, predlaÅ¾e se Arhitektura v2.0. Ovaj novi dizajn predstavlja migraciju s linearnog lanca na cikliÄki, stateful graf. Ovaj pristup omoguÄ‡uje modeliranje AI orkestracije kao stroja stanja (state machine), Å¡to je robustniji temelj za sloÅ¾ene operacije.   

KljuÄni koncept u v2.0 je AgentState objekt. Umjesto jednostavnog prosljeÄ‘ivanja podataka (npr. JSONâ†’stringâ†’string), cijeli sustav sada Äita i modificira centralizirani, a po potrebi i perzistentni, objekt stanja. Ovaj objekt sluÅ¾i kao temelj za agentno pamÄ‡enje, implementaciju petlji (loops) i donoÅ¡enje sloÅ¾enih logiÄkih odluka.   

Za implementaciju ove arhitekture u TypeScript ekosustavu, preporuÄuje se koriÅ¡tenje LangGraph.js. LangGraph.js je specifiÄno dizajniran za orkestraciju stateful agenata, pruÅ¾ajuÄ‡i eksplicitnu podrÅ¡ku za definiranje grafova, upravljanje stanjem i uvjetno grananje (conditional branching).   

1.3 Promjena Paradigme sa "Lanca" na "Sustav"
Inicijalna pretpostavka da je "sekvencijalno = kvalitetno" pokazala se pogreÅ¡nom u kontekstu modernih agentnih sustava. IstraÅ¾ivanja i najbolje prakse (npr. Anthropic, LangChain) pokazuju da se stvarna kvaliteta ne postiÅ¾e jednim, statiÄkim "savrÅ¡enim promptom", veÄ‡ kroz iterativno poboljÅ¡anje i refleksiju. Sekvencijalni lanac, po svojoj prirodi, ne moÅ¾e podrÅ¾ati takav iterativni proces.   

Prelazak na LangGraph  stoga nije samo tehniÄka nadogradnja; to je fundamentalna promjena paradigme. Uloga LogistiÄara (sada OrchestratorService) mijenja se iz "aktivnog upravitelja" koji imperativno poziva funkcije u "kontejner grafa" (graph container). Stvarna logika orkestracije (npr. "kada pozvati Pisca?", "treba li kritizirati nacrt?") viÅ¡e nije zakopana u if/else naredbama unutar TypeScript servisa, veÄ‡ je eksplicitno definirana u strukturi grafaâ€”njegovim rubovima (edges) i Ävorovima (nodes). Ovaj "graph-based" naÄin razmiÅ¡ljanja Äini sustav transparentnijim, modularnijim i lakÅ¡im za odrÅ¾avanje.   

II. Analiza Lanca i Redizajn Orkestracije: Implementacija pomoÄ‡u LangGraph.js
2.1 ZaÅ¡to LangGraph.js, a ne LCEL?
Dok je LangChain Expression Language (LCEL) izuzetno uÄinkovit za komponiranje linearnih sekvenci (chains), on postaje nepregledan i teÅ¾ak za odrÅ¾avanje kada se pokuÅ¡ava implementirati sloÅ¾ena, nelinearna logika. NaÅ¡ kljuÄni novi zahtjevâ€”"Mentor-kao-KritiÄar"â€”zahtijeva cikluse (loops), gdje se izlaz vraÄ‡a na prethodni korak radi poboljÅ¡anja.   

LangGraph je dizajniran upravo za ovaj scenarij. To je biblioteka za izgradnju stateful aplikacija koje zahtijevaju petlje, grananje i suradnju viÅ¡e agenata. OmoguÄ‡uje eksplicitnu i strogu kontrolu nad AgentState objektom u svakom koraku. PodrÅ¡ka za TypeScript (LangGraph.js) je zrela i omoguÄ‡uje definiranje strogo tipiziranog stanja, Å¡to je kljuÄno za robusnost sustava.   

2.2 Definicija Stanja Grafa (The AgentState)
SrediÅ¡nji dio nove arhitekture je AgentState. Ovo je TypeScript suÄelje (interface) koje definira "memoriju" sustava. Svaki Ävor (agent) u grafu prima cjelokupno stanje i vraÄ‡a aÅ¾uriranje (patch) tog stanja.   

PredloÅ¾ena AgentState shema (TypeScript):

TypeScript
import { BaseMessage } from "@langchain/core/messages";
// MessagesAnnotation osigurava da se poruke dodaju na listu,
// a ne da se prepisuju (state 'reducer')
import { MessagesAnnotation } from "@langchain/langgraph";

interface AgentState {
  // Ulaz i globalni kontekst
  userInput: string;          // Originalni upit korisnika
  storyContext: string;       // StatiÄki saÅ¾etak cijele priÄe (iz schema.ts)
  
  // Faza RAG-a i Usmjeravanja
  transformedQuery?: string;  // Upit rafiniran od strane Mentora (za RAG)
  ragContext?: string;      // DohvaÄ‡eni relevantni dijelovi (chunks)
  routingDecision?: "simple_retrieval" | "creative_generation" | "cannot_answer";

  // Faza Refleksije (Reflection) - Iterativna petlja
  draftCount: number;         // BrojaÄ iteracija petlje (za prekid)
  draft?: string;             // Trenutni nacrt od 'Pisca' (Anthropic)
  critique?: string;          // Posljednja kritika od 'Mentora' (Ollama)

  // Izlaz
  finalOutput?: string;       // KonaÄni odgovor za korisnika

  // Memorija razgovora (za stateful interakcije)
  messages: Annotated<BaseMessage, MessagesAnnotation>;
}
Ovaj model stanja  omoguÄ‡uje sustavu da u svakom trenutku prati gdje se nalazi u procesu, koji su podaci dohvaÄ‡eni i, Å¡to je najvaÅ¾nije, koliko je puta pokuÅ¡ao poboljÅ¡ati nacrt, Å¡to je temelj za "Reflection" petlju.   

2.3 Arhitektura Grafa: ÄŒvorovi i Uvjetni Rubovi
Originalne "Uloge" iz Arhitekture 4.0 sada postaju "ÄŒvorovi" (Nodes) u grafu, a logika odluÄivanja postaje "Rubovi" (Edges).   

ÄŒvorovi (Nodes) - NaÅ¡i Agenti i Alati:

transform_query: Poziva AI Mentora (Lokalni LLM) da transformira korisniÄki upit za RAG.

retrieve_context: Poziva LogistiÄara (TypeScript RAG alat) da dohvati kontekst.

route_task: Poziva AI Mentora (Lokalni LLM) da klasificira zadatak.

handle_simple_retrieval: Poziva AI Mentora (Lokalni LLM) da generira jednostavan odgovor.

generate_draft: Poziva Pisca (Cloud LLM) da napiÅ¡e prvi nacrt.

critique_draft: Poziva AI Mentora (Lokalni LLM) da kritizira nacrt.

refine_draft: Poziva Pisca (Cloud LLM) da poboljÅ¡a nacrt na temelju kritike.

Uvjetni Rubovi (Conditional Edges) - Logika Orkestracije:

Graf Ä‡e imati dva kljuÄna logiÄka grananja, implementirana pomoÄ‡u add_conditional_edges u LangGraph.js :   

Nakon route_task Ävora:

Ako je routingDecision == "simple_retrieval", graf prelazi na handle_simple_retrieval.

Ako je routingDecision == "creative_generation", graf prelazi na generate_draft.

InaÄe, graf prelazi na END (zavrÅ¡ava rad).

Nakon critique_draft Ävora:

Provjerava draftCount u AgentState.

Ako je draftCount < MAX_ITERATIONS (npr. 3), graf prelazi na refine_draft (nastavlja petlju).

Ako je draftCount >= MAX_ITERATIONS, graf prekida petlju i prelazi na END (koristeÄ‡i zadnji draft kao finalOutput).

Ovaj dizajn  je superioran jer razdvaja logiku (rubovi) od izvrÅ¡enja (Ävorovi). Razvojni tim sada moÅ¾e neovisno testirati i poboljÅ¡ati, na primjer, prompt za critique_draft Ävor bez utjecaja na route_task Ävor, Å¡to je bilo gotovo nemoguÄ‡e u starom, monolitnom OrchestratorService. Ovaj dizajn takoÄ‘er inherentno podrÅ¾ava "Human-in-the-Loop" (HITL) , gdje se graf moÅ¾e pauzirati kako bi stvarni korisnik (pisac) pregledao i odobrio critique prije nastavka petlje.   

III. PoboljÅ¡anje RAG-a: Obrazac "Transformacije Upita" (Query Transformation)
3.1 Problem: "Naivni RAG" i Narativna Nerelevantnost
Trenutni plan (LogistiÄar radi jednostavno vektorsko pretraÅ¾ivanje) koristi pristup poznat kao "Naivni RAG". Problem s ovim pristupom je Å¡to upiti korisnika za kreativno pisanje (npr. "NapiÅ¡i scenu gdje Ana osjeÄ‡a griÅ¾nju savjesti") Äesto semantiÄki nisu bliski kontekstu koji je stvarno potreban za pisanje te scene (npr. dokumenti koji opisuju "Anin profil lika", "dogaÄ‘aj X koji je izazvao griÅ¾nju savjesti", "Anin odnos s Markom"). Ovo "semantiÄko nepodudaranje" dovodi do dohvaÄ‡anja nerelevantnog RAG konteksta i posljediÄno slabijeg generiranog teksta.   

3.2 RjeÅ¡enje: "Mentor-prije-RAG-a" (Obrazac Transformacije Upita)
Implementirat Ä‡e se obrazac Query Transformation (Transformacija Upita)  koristeÄ‡i AI Mentora (Lokalni LLM).   

Tijek implementacije (ÄŒvor transform_query):

Korisnik unosi: "NapiÅ¡i scenu gdje se Ana i Marko svaÄ‘aju oko nasljedstva."

Ovaj upit ne ide odmah u RAG pretraÅ¾ivanje. Prvo se Å¡alje AI Mentoru (Lokalni LLM).

AI Mentor dobiva sistemsku uputu (system prompt): "Ti si ekspert za RAG. Korisnikov upit je zahtjev za kreativno pisanje. Pretvori ovaj upit u 3-5 specifiÄnih, hipotetskih upita optimiziranih za pretraÅ¾ivanje vektorske baze kako bi se prikupio sav potreban kontekst za pisanje scene. Fokusiraj se na dohvaÄ‡anje profila likova, relevantnih proÅ¡lih dogaÄ‘aja, lokacija i kljuÄnih objekata." (Ovaj pristup je sliÄan HyDE (Hypothetical Document Embeddings) obrascu ).   

AI Mentor vraÄ‡a niz stringova, npr.: ``.

LogistiÄar (sada Ävor retrieve_context) izvrÅ¡ava 5 odvojenih vektorskih pretraÅ¾ivanja i spaja (fusion) sve jedinstvene rezultate.   

Prednost ovog pristupa je dobivanje znatno bogatijeg i relevantnijeg konteksta  prije nego Å¡to Pisac (Cloud LLM) uopÄ‡e zapoÄne s generiranjem.   

3.3 Napredna Preporuka: "Stateful" RAG za Dugotrajne Narative
ObiÄni RAG je "stateless"â€”tretira svaki upit kao izolirani dogaÄ‘aj. MeÄ‘utim, priÄe su inherentno "stateful"â€”dogaÄ‘aji u Sceni 1 moraju utjecati na kontekst u Sceni 50 da bi se odrÅ¾ala koherentnost.   

IstraÅ¾ivaÄki rad na ComoRAG (Cognitive-inspired Memory-Organized RAG)  nudi rjeÅ¡enje: "dinamiÄki memorijski radni prostor" (dynamic memory workspace). U praksi, to znaÄi da RAG sustav mora istovremeno baratati s dva tipa konteksta:   

SpecifiÄni Kontekst: Relevantni dijelovi (chunks) za trenutni upit (dohvaÄ‡eni pomoÄ‡u Transformacije Upita, kako je opisano u 3.2).

Globalni Kontekst: SaÅ¾etak kljuÄnih toÄaka radnje ("Story So Far") koji se dinamiÄki aÅ¾urira i odrÅ¾ava (vjerojatno unutar samog AgentState ili u zasebnoj saÅ¾etoj bazi).

Modificirani Ävor retrieve_context stoga mora spojiti (fusion) ova dva skupa podataka. Ovo osigurava da Pisac uvijek ima pristup i mikro kontekstu (npr. "opis sobe") i makro kontekstu priÄe (npr. "Äinjenica da je Marko upravo izgubio posao, Å¡to utjeÄe na njegov ton u svaÄ‘i"). Ovo je kljuÄno za odrÅ¾avanje dugoroÄne koherentnosti likova i radnje.   

IV. ProÅ¡irenje Uloge "Mentora": Implementacija "Reflection" Petlje
4.1 Problem: NeiskoriÅ¡ten Potencijal Hibridne Arhitekture
Originalna ideja da AI Mentor (Lokalni LLM) samo piÅ¡e prompt za Pisca (Cloud LLM) predstavlja neadekvatno i neuÄinkovito koriÅ¡tenje resursa. Ako je lokalni model dovoljno sofisticiran da napiÅ¡e "savrÅ¡en" prompt, vjerojatno je dovoljno sofisticiran i da obavlja znatno korisnije analitiÄke zadatke.   

IstraÅ¾ivanja i praktiÄna iskustva s hibridnim sustavima pokazuju da lokalni modeli, iako moÅ¾da manje "kreativni" od masivnih cloud modela, Äesto briljiraju u strukturiranim, analitiÄkim zadacima koji zahtijevaju dosljednost i praÄ‡enje pravila. Kritiziranje teksta prema zadanim smjernicama je upravo takav zadatak.   

4.2 RjeÅ¡enje: Obrazac "Reflection" (Generiraj-Kritiziraj-PoboljÅ¡aj)
Umjesto da se oslanjamo na jedan "savrÅ¡en udarac" (jedan prompt, jedan izlaz), nova arhitektura usvaja obrazac iterativnog poboljÅ¡anja. Ovaj je obrazac formaliziran u industriji kao Agentni Obrazac Refleksije (Reflection Pattern)  ili Self-Refine / CRITIC petlja.   

Ovaj obrazac je u srcu Anthropic-ove vlastite "Constitutional AI", gdje se AI modeli treniraju i usmjeravaju kroz proces samokritike. Arhitektura v2.0 primjenjuje isti princip u stvarnom vremenu (at inference time), koristeÄ‡i hibridni sustav (Lokalni LLM kritizira Cloud LLM).   

4.3 Implementacija "Mentor-KritiÄar" Petlje
Ova petlja se implementira kroz tri Ävora u LangGraphu: generate_draft, critique_draft i refine_draft.

Korak 1: Generiranje Nacrta (ÄŒvor generate_draft)

Pisac (Anthropic, npr. Claude 3.5 Sonnet ) prima RAG kontekst (specifiÄni + globalni) i korisniÄki upit.   

Generira prvi nacrt (draft). Ovaj nacrt se ne Å¡alje korisniku. Sprema se u AgentState.

Korak 2: Kritika Nacrta (ÄŒvor critique_draft)

Nacrt se Å¡alje natrag AI Mentoru (Ollama, Lokalni LLM).

AI Mentor sada dobiva potpuno drugaÄiju personu (sistemsku uputu):

Code snippet
"Ti si 'AI Mentor', strogi, ali poÅ¡teni urednik kreativnog pisanja.[50, 51] Tvoj zadatak je pregledati sljedeÄ‡i NACRT i osigurati da je 100% usklaÄ‘en s pruÅ¾enim KONTEKSTOM (RAG smjernicama). Budi precizan i nepopustljiv u vezi dosljednosti.

KONTEKST (Smjernice koje se moraju poÅ¡tovati):
{ragContext}

NACRT (Tekst koji se pregledava):
{draft}

Tvoj zadatak [52, 53]:
1.  **Provjera Koherentnosti:** PronaÄ‘i BILO KAKVE ÄinjeniÄne kontradikcije izmeÄ‘u NACRTA i KONTEKSTA. Jesu li imena likova, lokacije i proÅ¡li dogaÄ‘aji toÄno preneseni?
2.  **Provjera Dosljednosti Lika:** Odstupa li ponaÅ¡anje lika u NACRTU od njegovog profila u KONTEKSTU?
3.  **Provjera Potpunosti:** Je li NACRT ispunio SVE zahtjeve iz originalnog korisniÄkog upita?

Vrati samo JSON objekt sa svojim povratnim informacijama [47]:
{
  "issues": ["Popis pronaÄ‘enih problema..."],
  "plan":,
  "score": <ocjena od 0-100 o usklaÄ‘enosti s kontekstom>,
  "stop": <true ako je nacrt savrÅ¡en, false ako treba poboljÅ¡anje>
}
Korak 3: PoboljÅ¡anje Nacrta (ÄŒvor refine_draft)

Pisac (Anthropic) poziva se ponovno.

Ovaj put prima: {originalni upit} + {RAG kontekst} + {svoj prvi nacrt} + {JSON kritiku od Mentora}.

Uputa: "PoboljÅ¡aj svoj originalni nacrt. Strogo slijedi upute za ispravak iz JSON kritike kako bi rijeÅ¡io navedene probleme."

Korak 4: Petlja

LangGraph uvjetni rub  provjerava draftCount i stop zastavicu iz kritike te ili vraÄ‡a na Korak 2 (ako treba joÅ¡ poboljÅ¡anja) ili zavrÅ¡ava petlju.   

4.4 Stvaranje SuradniÄke Debate (Multi-Agent Collaboration)
Ovim dizajnom stvorena je "soba za pisce" (writer's room) , a ne samo proizvodna traka. Sustav implementira suradniÄku debatu izmeÄ‘u dva specijalizirana agenta :   

Pisac (Anthropic): Iznimno kreativan, elokventan, ali sklon "haluciniranju" ili kreativnom skretanju s teme.   

Mentor (Ollama): AnalitiÄan, metodiÄan, fokusiran na pravila i dosljednost s kontekstom.   

Ova namjerno stvorena "tenzija" izmeÄ‘u dva razliÄita modela (Cloud vs. Local) proizvodi bolji i pouzdaniji rezultat nego da isti model pokuÅ¡ava i pisati i kritizirati sam sebe. Lokalni model efektivno djeluje kao "Äuvar" (guardrail)  za skuplji cloud model, osiguravajuÄ‡i da njegove skupe pogreÅ¡ke ili odstupanja od zadanog narativa budu uhvaÄ‡ene i ispravljene prije nego Å¡to doÄ‘u do korisnika. Ovo je robustan, multi-agentni obrazac suradnje.   

V. Hibridna Strategija OdluÄivanja: Inteligentno Usmjeravanje (Smart Routing)
5.1 Problem: TroÅ¡ak i Latencija "Uvijek-Cloud" Pristupa
Originalna Arhitektura 4.0 ima fundamentalni nedostatak u pogledu uÄinkovitosti: ona uvijek poziva sva tri AI modela (RAG pretraga, Lokalni LLM za prompt, Cloud LLM za pisanje) za svaki pojedini upit.

Ovo je nepotrebno, sporo i skupo. Mnogi korisniÄki upiti neÄ‡e zahtijevati kreativno generiranje. Na primjer, upit poput: "Kako se zove Anin otac?" ili "Podsjeti me Å¡to se dogodilo u Sceni 3" zahtijeva samo dohvaÄ‡anje Äinjenica (retrieval), a ne skupo kreativno pisanje od strane Anthropic-a.   

5.2 RjeÅ¡enje: "Mentor-kao-UsmjerivaÄ" (LLM-as-Router)
Iskoristit Ä‡e se AI Mentor (Lokalni LLM) kao lagani klasifikator namjere (intent classifier) ili usmjerivaÄ (router). Ovaj se Ävor izvrÅ¡ava nakon RAG-a, ali prije pozivanja skupog Pisca.   

Ovo je dobro dokumentiran arhitektonski obrazac za optimizaciju hibridnih sustava, gdje se lagani, lokalni model koristi za trijaÅ¾u zadataka, Äime se drastiÄno smanjuju troÅ¡kovi i latencija slanjem samo najsloÅ¾enijih upita skupljim modelima.   

5.3 Implementacija (ÄŒvor route_task)
Nakon Å¡to su Ävorovi transform_query i retrieve_context (RAG) zavrÅ¡eni, sustav posjeduje sav potreban kontekst za donoÅ¡enje odluke.

Poziva se AI Mentor (Lokalni LLM) s posebnim promptom za usmjeravanje :   

Code snippet
Ti si 'AI LogistiÄar' i usmjerivaÄ zadataka. Tvoj zadatak je klasificirati korisniÄki upit u JEDNU od tri kategorije, na temelju upita i dohvaÄ‡enog RAG konteksta.

KATEGORIJE:
1.  **simple_retrieval**: Upit traÅ¾i jednostavnu Äinjenicu, saÅ¾etak ili informaciju koja je EKSPLICITNO prisutna u RAG kontekstu. (Npr. "Tko je...", "Å to je...", "Podsjeti me...", "Gdje je...").
2.  **creative_generation**: Upit zahtijeva novo, kreativno pisanje (npr. pisanje nove scene, dijaloga, opisa, brainstorminga) koje se oslanja na RAG kontekst, ali NIJE direktno u njemu. (Npr. "NapiÅ¡i...", "OpiÅ¡i...", "Generiraj...", "Zammisli...").
3.  **cannot_answer**: Upit traÅ¾i neÅ¡to Å¡to nije povezano s priÄom ili RAG kontekst ne sadrÅ¾i relevantne informacije za odgovor.

KORISNIÄŒKI UPIT:
{userInput}

DOHVAÄ†ENI RAG KONTEKST:
{ragContext}

Vrati samo JEDNU rijeÄ - naziv kategorije (npr. "simple_retrieval").
Logika grafa (definirana u add_conditional_edges ) zatim usmjerava proces na temelju ovog stringa:   

Za "simple_retrieval", poziva se Ävor handle_simple_retrieval, gdje AI Mentor (Lokalni LLM) sam generira odgovor na temelju konteksta. Ovo je brzo, jeftino i privatno.

Za "creative_generation", pokreÄ‡e se skupi (Anthropic) Pisac i ulazi se u "Reflection" petlju.

5.4 Stvaranje TroÅ¡kovno UÄinkovitog Hibridnog Sustava
Spajanjem obrasca "Reflection" i "Routing", AI Mentor (Ollama/Llama) postaje srce i "mozak" cijelog sustava. Pisac (Anthropic/Claude) degradiran je iz glavnog izvrÅ¡itelja u moÄ‡an, ali specijalizirani "alat"  kojeg AI Mentor poziva samo po potrebi.   

Ova arhitektura  inteligentno balansira resurse. Koristi lokalni LLM za veÄ‡inu "razmiÅ¡ljanja" (transformacija upita, klasifikacija namjere, kritika nacrta, jednostavni odgovori), a skupi cloud LLM koristi iskljuÄivo za zadatak u kojem je nezamjenjivâ€”generiranje vrhunskog, elokventnog kreativnog teksta. Ovo predstavlja najrobusniji i troÅ¡kovno najuÄinkovitiji hibridni obrazac dostupan danas.   

VI. SaÅ¾etak PreporuÄene Arhitekture (v2.0) i Tablice
6.1 Novi Arhitektonski Obrazac
Obrazac: Stateful Multi-Agent Sustav  temeljen na LangGraph.js.   

Agenti (ÄŒvorovi):

AI Mentor (Lokalni LLM - Ollama): Djeluje kao Transformer Upita, UsmjerivaÄ (Router) i KritiÄar (Critic).

Pisac (Cloud LLM - Anthropic): Djeluje kao specijalizirani alat za kreativno generiranje i poboljÅ¡anje.

KljuÄni Obrasci (Patterns) KoriÅ¡teni:

Query Transformation  za napredni RAG.   

Stateful RAG  za narativnu koherentnost.   

LLM-as-Router  za hibridno usmjeravanje i uÅ¡tedu troÅ¡kova.   

Reflection Pattern (Critique-Refine Loop)  za iterativno poboljÅ¡anje kvalitete.   

6.2 PredloÅ¾eni Tijek (Flow v2.0)
Korisnik -> ÄŒvor transform_query (Mentor) -> **

-> ÄŒvor retrieve_context (LogistiÄar RAG) -> **

-> ÄŒvor route_task (Mentor) -> **

-> Uvjetni Rub (Routing):

PUT A (Simple): -> handle_simple_retrieval (Mentor) -> END

PUT B (Creative): -> generate_draft (Pisac) -> **

-> ÄŒvor critique_draft (Mentor) -> **

-> Uvjetni Rub (Reflection Petlja):

Ako draftCount < 3 I critique.stop == false: -> refine_draft (Pisac) -> ** -> Vrati se na Korak 5.

InaÄe: -> END (KonaÄni draft postaje finalOutput).

6.3 KljuÄne Definicijske Tablice
SljedeÄ‡e tablice pruÅ¾aju jasan tehniÄki pregled za implementacijski tim.

Tablica 1: Definicija SrediÅ¡njeg Stanja (AgentState) Svrha: Ovo suÄelje je temelj LangGraph arhitekture i sluÅ¾i kao strogo tipizirani ugovor o podacima koji se prenosi izmeÄ‘u svih Ävorova.   

KljuÄ (Property)	Tip (TypeScript)	Opis Uloge	ÄŒvor Koji PiÅ¡e	ÄŒvorovi Koji ÄŒitaju
userInput	string	Originalni upit korisnika.	START	transform_query, route_task
storyContext	string	StatiÄki globalni kontekst priÄe.	START	transform_query
transformedQuery	string | null	Upit optimiziran za RAG.	transform_query	retrieve_context
ragContext	string | null	DohvaÄ‡eni relevantni dijelovi (chunks).	retrieve_context	route_task, handle_simple_retrieval, generate_draft, critique_draft
routingDecision	string | null	Odluka o vrsti zadatka.	route_task	Samo uvjetni rub
draftCount	number	BrojaÄ iteracija petlje.	START (na 0), critique_draft (++)	Samo uvjetni rub
draft	string | null	Trenutna verzija kreativnog teksta.	generate_draft, refine_draft	critique_draft, END
critique	string | null	JSON kritika od strane Mentora.	critique_draft	refine_draft, Uvjetni rub
finalOutput	string | null	KonaÄni odgovor za slanje korisniku.	handle_simple_retrieval, END	-
messages	Annotated<BaseMessage>	Povijest razgovora za pamÄ‡enje.	START, END	Svi Ävorovi (po potrebi)
Tablica 2: Usporedba Arhitekture v4.0 (Lanac) i v2.0 (Graf) Svrha: Ovaj saÅ¾etak vizualno prikazuje nadogradnje i opravdava migraciju s jednostavnog lanca na robustan, stateful graf.   

Kriterij	Arhitektura 4.0 (Sekvencijalni Lanac)	Arhitektura v2.0 (Stateful Graf)
Okvir (Framework)	
Jednostavni TypeScript / LCEL 

LangGraph.js 

Tijek (Flow)	
Striktno linearan (RAG -> Mentor -> Pisac) 

CikliÄki, uvjetovan, stateful 

Upravljanje Stanja	Implicitno (prosljeÄ‘ivanje parametara)	
Eksplicitno (centralni AgentState objekt) 

Uloga Mentora	Samo Pisanje Prompta	
ViÅ¡estruka: Transformator Upita, UsmjerivaÄ, KritiÄar 

RAG Metodologija	
Naivni RAG (jedan upit) 

Napredni RAG (Query Transformation + Stateful Context) 

Iteracija Kvalitete	Nema (jedan prolaz, "single-shot")	
UgraÄ‘ena "Reflection" petlja (Generiraj-Kritiziraj-PoboljÅ¡aj) 

Upravljanje TroÅ¡kovima	Nema (uvijek poziva Cloud LLM)	
Hibridno Usmjeravanje (Cloud LLM samo za kompleksne zadatke) 

  
VII. ZAKLJUÄŒAK: Implementacijski Putokaz i SljedeÄ‡i Koraci
7.1 SaÅ¾etak Preporuka
Arhitektura v2.0, temeljena na LangGraph.js, rjeÅ¡ava temeljna ograniÄenja originalnog dizajna. Ona transformira sustav iz krutog lanca u fleksibilan, inteligentan i samoispravljajuÄ‡i organizam. KljuÄne preporuke su:

Usvojiti LangGraph.js kao temelj orkestracije za upravljanje stateful, cikliÄkim tijekovima.

Definirati strogo tipizirani AgentState kao centralni ugovor o podacima.

Implementirati AI Mentora (Ollama) kao viÅ¡enamjenskog agenta koji obavlja zadatke Query Transformation, Routing i Critique.

Implementirati Pisca (Anthropic) kao specijalizirani "alat" kojeg Mentor poziva iskljuÄivo za zadatke generiranja visoke kreativnosti.

7.2 SljedeÄ‡i Koraci za Implementaciju
PreporuÄuje se fazni pristup implementaciji grafa:

Korak 1 (Postavljanje): Inicijalizirati LangGraph.js projekt. Definirati i instancirati AgentState suÄelje i StateGraph.   

Korak 2 (Implementacija RAG-a): Implementirati Ävorove transform_query i retrieve_context. Testirati i validirati kvalitetu dohvaÄ‡enog konteksta koriÅ¡tenjem obrasca Transformacije Upita.

Korak 3 (Implementacija Usmjeravanja): Implementirati route_task Ävor i handle_simple_retrieval Ävor. Dodati prve add_conditional_edges. Testirati usmjeravanje (jednostavno vs. kreativno).   

Korak 4.a (Implementacija "Reflection" ÄŒvorova): 
   - Dodati tri kljuÄna Ävora u `ai.nodes.ts`:
     - **generateDraftNode**: Koristi Cloud LLM (Anthropic Claude 3.5 Sonnet) za generiranje poÄetne verzije priÄe. Prima RAG kontekst i korisniÄke zahtjeve, generira prvi nacrt koji se sprema u `state.storyDraft`.
     - **critiqueDraftNode**: Koristi Lokalni LLM (Ollama) za analizu trenutne verzije. VraÄ‡a strukturiranu kritiku u JSON formatu s ocjenama po kriterijima (1-10), konkretnim prijedlozima i `stop: true/false` zastavicom. TakoÄ‘er poveÄ‡ava `draftCount`.
     - **refineDraftNode**: Koristi Cloud LLM (Anthropic Claude 3.5 Haiku za brÅ¾e iteracije) za poboljÅ¡anje nacrta na temelju kritike. Prima originalni nacrt + JSON kritiku i generira poboljÅ¡anu verziju.
   - Svi Ävorovi moraju imati robusno error handling i detaljno logiranje za praÄ‡enje iteracija.

Korak 4.b (AÅ¾uriranje Grafa - Povezivanje Petlje):
   - U `ai.graph.ts`:
     - Ukloniti postojeÄ‡i `generate_draft_placeholder` Ävor
     - Dodati nove Ävorove iz koraka 4.a u graf koristeÄ‡i `.addNode()` metodu
     - Implementirati uvjetni rub nakon `critiqueDraftNode` pomoÄ‡u `addConditionalEdges`:
       - Provjeriti `stop: true` iz kritike â†’ prekid petlje, prelazak na finalizaciju
       - Provjeriti `draftCount >= 3` â†’ prekid petlje nakon maksimalno 3 iteracije
       - InaÄe â†’ nastavak na `refineDraftNode` koji vraÄ‡a tok na `generateDraftNode`
     - Osigurati ispravno povezivanje s ostatkom grafa (ulaz iz route_story, izlaz prema END)
   - Testirati cjelokupnu petlju s razliÄitim scenarijima (brzi prekid, maksimalne iteracije)   

Korak 5 (Evaluacija): Provesti kvantitativnu evaluaciju (Evals)  kako bi se izmjerilo poboljÅ¡anje kvalitete izlaza i smanjenje troÅ¡kova (broj poziva Cloud LLM-a) u usporedbi s originalnom Arhitekturom 4.0.   

VIII. PLAN POPRAVKA: POSTAVLJANJE VEKTORSKE BAZE

8.1 Dijagnoza Problema
Tijekom prvog testa AI agentnog sustava na ruti `/api/ai/test-agent`, identificiran je kritiÄni problem s RAG (Retrieval-Augmented Generation) komponentom. GreÅ¡ka "GreÅ¡ka prilikom dohvaÄ‡anja konteksta iz vektorske baze" u `ragContext` polju ukazuje na sljedeÄ‡e nedostatke:

1. **Nedostaje pgvector ekstenzija** - PostgreSQL baza podataka nema instaliranu pgvector ekstenziju koja je preduvjet za rad s vektorskim tipovima podataka
2. **Ne postoji tablica `story_architect_embeddings`** - PGVectorStore pokuÅ¡ava pristupiti tablici koja nije kreirana u bazi podataka
3. **Nema definicije u Drizzle shemi** - Tablica za vektorske embeddings nije definirana u `schema.ts` datoteci

Ovi nedostaci onemoguÄ‡avaju funkcioniranje RAG sustava koji je kljuÄan za dohvaÄ‡anje relevantnog konteksta iz priÄe.

8.2 Arhitektura RjeÅ¡enja
RjeÅ¡enje slijedi "Drizzle-ispravan" pristup koji odrÅ¾ava integritet postojeÄ‡eg razvojnog workflow-a projekta. Umjesto kreiranja ruÄnih SQL migracija, koristit Ä‡e se kombinacija:
- Drizzle schema definicija za tablicu
- Jednokratna skripta za omoguÄ‡avanje pgvector ekstenzije
- PostojeÄ‡i `pnpm db:push` mehanizam za sinkronizaciju sheme

8.3 Detaljan Plan Implementacije

### Korak 1: Kreiranje Skripte za Ekstenziju

**Cilj**: Kreirati jednokratnu skriptu koja Ä‡e omoguÄ‡iti pgvector ekstenziju u PostgreSQL bazi.

**Lokacija**: `server/scripts/setup-pgvector.ts`

**Implementacija**:
```typescript
import { drizzle } from 'drizzle-orm/postgres-js';
import postgres from 'postgres';
import * as dotenv from 'dotenv';
import path from 'path';

// UÄitaj environment varijable
dotenv.config({ path: path.resolve(__dirname, '../.env') });

async function setupPgVector() {
  const connectionString = process.env.DATABASE_URL;
  
  if (!connectionString) {
    console.error('âŒ DATABASE_URL environment variable is not set!');
    process.exit(1);
  }

  console.log('ğŸ”§ Connecting to database...');
  
  const sql = postgres(connectionString);
  const db = drizzle(sql);

  try {
    // Provjeri postoji li veÄ‡ ekstenzija
    const result = await sql`
      SELECT * FROM pg_extension WHERE extname = 'vector'
    `;
    
    if (result.length > 0) {
      console.log('âœ… pgvector extension is already installed');
    } else {
      console.log('ğŸ“¦ Installing pgvector extension...');
      await sql`CREATE EXTENSION IF NOT EXISTS vector`;
      console.log('âœ… pgvector extension installed successfully');
    }
    
    // Provjeri verziju
    const version = await sql`
      SELECT extversion FROM pg_extension WHERE extname = 'vector'
    `;
    
    if (version.length > 0) {
      console.log(`ğŸ“Œ pgvector version: ${version[0].extversion}`);
    }
    
  } catch (error) {
    console.error('âŒ Error setting up pgvector:', error);
    process.exit(1);
  } finally {
    await sql.end();
    console.log('ğŸ”’ Database connection closed');
  }
}

// Pokreni setup
setupPgVector().then(() => {
  console.log('âœ¨ pgvector setup completed!');
  console.log('ğŸ“ Next step: Run "pnpm db:push" to create the embeddings table');
}).catch((error) => {
  console.error('Failed to setup pgvector:', error);
  process.exit(1);
});
```

### Korak 2: AÅ¾uriranje schema.ts

**Cilj**: Dodati definiciju tablice `storyArchitectEmbeddings` u Drizzle shemu.

**Lokacija**: `server/src/schema/schema.ts`

**Implementacija** (dodati na kraj datoteke):
```typescript
// Custom type za pgvector - sigurna implementacija
export const vector = customType<{ data: number[]; driverData: string }>({
  dataType() { 
    return 'vector(1536)'; // OpenAI text-embedding-3-small koristi 1536 dimenzija
  },
  toDriver(value: number[]): string {
    // Pretvori array brojeva u PostgreSQL vector format
    return JSON.stringify(value);
  },
  fromDriver(value: string): number[] {
    // Pretvori PostgreSQL vector string natrag u array
    return JSON.parse(value);
  },
});

// Tablica za AI vektorske embeddings
export const storyArchitectEmbeddings = pgTable('story_architect_embeddings', {
  id: uuid('id').primaryKey().defaultRandom(),
  content: text('content').notNull(),
  metadata: jsonb('metadata').default({}).$type<{
    docId?: string;
    projectId?: string;
    chunkIndex?: number;
    sourceType?: 'character' | 'scene' | 'location' | 'project';
    [key: string]: any;
  }>(),
  vector: vector('vector').notNull(),
  createdAt: timestamp('created_at').defaultNow(),
}, (table) => ({
  // Indeks za brÅ¾e vektorsko pretraÅ¾ivanje koristeÄ‡i cosine distance
  vectorIdx: index('idx_story_architect_embeddings_vector')
    .using('ivfflat', table.vector.op('vector_cosine_ops'))
    .with({ lists: 100 }),
  // Dodatni indeksi za filtriranje
  metadataProjectIdIdx: index('idx_embeddings_metadata_project_id')
    .on(sql`(metadata->>'projectId')`),
  createdAtIdx: index('idx_embeddings_created_at').on(table.createdAt),
}));

// Relacije za embeddings tablicu
export const storyArchitectEmbeddingsRelations = relations(storyArchitectEmbeddings, ({ }) => ({
  // Embeddings tablica nema direktne FK veze, koristi metadata za reference
}));
```

### Korak 3: AÅ¾uriranje ai.retriever.ts

**Cilj**: Dodati provjeru postojanja tablice i poboljÅ¡ati error handling.

**Lokacija**: `server/src/services/ai/ai.retriever.ts`

**Implementacija** (dodati prije `getRelevantContext` funkcije):
```typescript
/**
 * Provjerava postoji li tablica u bazi podataka
 */
async function checkTableExists(tableName: string): Promise<boolean> {
  try {
    const db = await getDatabase();
    const result = await db.execute(sql`
      SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name = ${tableName}
      )
    `);
    return result.rows[0]?.exists || false;
  } catch (error) {
    console.error(`Error checking if table ${tableName} exists:`, error);
    return false;
  }
}
```

**AÅ¾uriranje `getRelevantContext` funkcije**:
```typescript
export async function getRelevantContext(query: string, k: number = 5): Promise<string> {
  try {
    // Provjeri postoji li tablica prije pokuÅ¡aja dohvaÄ‡anja
    const tableExists = await checkTableExists('story_architect_embeddings');
    if (!tableExists) {
      console.warn('Vector table not found. Please run setup-pgvector.ts and db:push');
      return "Vektorska baza joÅ¡ nije konfigurirana. Molimo pokrenite postavljanje vektorske baze.";
    }

    // PostojeÄ‡i kod za dohvaÄ‡anje...
    const store = await getVectorStore();
    const results = await store.similaritySearch(query, k);

    if (results.length === 0) {
      return "Nema pronaÄ‘enog relevantnog konteksta.";
    }

    return results
      .map((doc) => doc.pageContent)
      .join("\n\n---\n\n");

  } catch (error) {
    console.error("Error during RAG retrieval:", error);
    // Detaljnija poruka greÅ¡ke za lakÅ¡e debugiranje
    if (error instanceof Error) {
      console.error("Error details:", error.message);
      console.error("Stack trace:", error.stack);
    }
    return "GreÅ¡ka prilikom dohvaÄ‡anja konteksta iz vektorske baze.";
  }
}
```

### Korak 4: AÅ¾uriranje package.json

**Cilj**: Dodati automatiziranu skriptu za postavljanje AI infrastrukture.

**Lokacija**: `server/package.json`

**Implementacija** (dodati u `scripts` sekciju):
```json
{
  "scripts": {
    // ... postojeÄ‡e skripte ...
    "setup:ai": "tsx scripts/setup-pgvector.ts && pnpm db:push",
    "setup:ai:check": "tsx scripts/setup-pgvector.ts"
  }
}
```

### Korak 5: Upute za IzvrÅ¡enje

**Redoslijed pokretanja naredbi**:

1. **Inicijalno postavljanje** (izvrÅ¡ava se jednom):
   ```bash
   cd server
   pnpm setup:ai
   ```
   
   Ova naredba Ä‡e:
   - Pokrenuti `setup-pgvector.ts` skriptu koja instalira pgvector ekstenziju
   - Automatski pokrenuti `db:push` koji Ä‡e kreirati `story_architect_embeddings` tablicu

2. **Provjera statusa** (opcionalno):
   ```bash
   pnpm setup:ai:check
   ```
   
   Ova naredba samo provjerava je li pgvector ekstenzija instalirana.

3. **Testiranje**:
   ```bash
   pnpm dev
   # U drugom terminalu:
   # Testirati /api/ai/test-agent endpoint ponovno
   ```

**Napomene za proizvodnju**:
- Za cloud PostgreSQL providere (Supabase, Neon, Railway), pgvector je obiÄno veÄ‡ dostupan
- Za self-hosted PostgreSQL, potrebno je instalirati pgvector paket na server nivou
- PreporuÄuje se dokumentirati verziju pgvector ekstenzije u README.md

8.4 Dodatne Preporuke za BuduÄ‡nost

1. **Skripta za popunjavanje poÄetnih embeddings**:
   - Kreirati `scripts/populate-embeddings.ts` koja Ä‡e generirati embeddings za postojeÄ‡e podatke

2. **Monitoring i maintenance**:
   - Dodati endpoint za provjeru zdravlja vektorske baze
   - Implementirati periodiÄko reindeksiranje za optimalne performanse

3. **Testovi**:
   - Dodati unit testove za vector customType
   - Dodati integraciju testove za RAG pipeline

Ovaj plan osigurava robusnu implementaciju vektorske baze koja se savrÅ¡eno uklapa u postojeÄ‡u Drizzle/TypeScript arhitekturu projekta.

